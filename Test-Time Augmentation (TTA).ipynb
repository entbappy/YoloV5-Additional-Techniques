{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Test-Time Augmentation (TTA).ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LFOybMYSWwPo"},"outputs":[],"source":["!git clone https://github.com/ultralytics/yolov5"]},{"cell_type":"code","source":["%%bash\n","cd yolov5\n","pip install -r requirements.txt"],"metadata":{"id":"hWoWdQNNXXal"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test Normally\n","This command tests YOLOv5x on COCO val2017 at image size 640 pixels. yolov5x.pt is the largest and most accurate model available. Other options are yolov5s.pt, yolov5m.pt and yolov5l.pt, or you own checkpoint from training a custom dataset ./weights/best.pt"],"metadata":{"id":"EYOVpzhwX9dM"}},{"cell_type":"code","source":["!python /content/yolov5/val.py --weights yolov5x.pt --data coco128.yaml --img 640 --half"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cp0n1lFRX35y","executionInfo":{"status":"ok","timestamp":1644072911042,"user_tz":-330,"elapsed":60429,"user":{"displayName":"Rishav Dash","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13111845716671250348"}},"outputId":"77ff67d6-b25e-4f36-d9c1-08aac87818b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco128.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\n","YOLOv5 ðŸš€ v6.0-237-gdc7e093 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5x.pt to yolov5x.pt...\n","100% 166M/166M [00:01<00:00, 111MB/s]\n","\n","Fusing layers... \n","Model Summary: 444 layers, 86705005 parameters, 0 gradients\n","\n","Dataset not found, missing paths: ['/content/datasets/coco128/images/train2017']\n","Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n","100% 6.66M/6.66M [00:00<00:00, 57.5MB/s]\n","Dataset autodownload success, saved to /content/datasets\n","\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017' images and labels...128 found, 0 missing, 2 empty, 0 corrupt: 100% 128/128 [00:00<00:00, 563.27it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:19<00:00,  4.81s/it]\n","                 all        128        929      0.798      0.752      0.823      0.623\n","Speed: 0.3ms pre-process, 119.1ms inference, 4.3ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1myolov5/runs/val/exp\u001b[0m\n"]}]},{"cell_type":"markdown","source":["## Test with TTA\n","Append --augment to any existing val.py command to enable TTA, and increase the image size by about 30% for improved results. Note that inference with TTA enabled will typically take about 2-3X the time of normal inference as the images are being left-right flipped and processed at 3 different resolutions, with the outputs merged before NMS. Part of the speed decrease is simply due to larger image sizes (832 vs 640), while part is due to the actual TTA operations."],"metadata":{"id":"1wwcgbQlYmyV"}},{"cell_type":"code","source":["!python /content/yolov5/val.py --weights yolov5x.pt --data coco128.yaml --img 832 --augment --half"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mLpwN5_8YGww","executionInfo":{"status":"ok","timestamp":1644073506844,"user_tz":-330,"elapsed":72757,"user":{"displayName":"Rishav Dash","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13111845716671250348"}},"outputId":"fdaab395-994a-45f0-a5c8-1b9ebb1ecaa4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco128.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=832, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=True, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=yolov5/runs/val, name=exp, exist_ok=False, half=True, dnn=False\n","YOLOv5 ðŸš€ v6.0-237-gdc7e093 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Fusing layers... \n","Model Summary: 444 layers, 86705005 parameters, 0 gradients\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:57<00:00, 14.47s/it]\n","                 all        128        929      0.768      0.795      0.853      0.662\n","Speed: 0.9ms pre-process, 426.8ms inference, 3.6ms NMS per image at shape (32, 3, 832, 832)\n","Results saved to \u001b[1myolov5/runs/val/exp4\u001b[0m\n"]}]},{"cell_type":"markdown","source":["## Inference"],"metadata":{"id":"RAvM7VCTbK1Q"}},{"cell_type":"code","source":["pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"fBJYoNn8bSla","executionInfo":{"status":"ok","timestamp":1644073662811,"user_tz":-330,"elapsed":95,"user":{"displayName":"Rishav Dash","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13111845716671250348"}},"outputId":"7d4b2402-13c1-4a12-e902-a91640dab152"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","source":["!python /content/yolov5/detect.py --weights yolov5s.pt --img 832 --source /content/yolov5/data/images --augment"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M2434u7EbMq6","executionInfo":{"status":"ok","timestamp":1644073704139,"user_tz":-330,"elapsed":7610,"user":{"displayName":"Rishav Dash","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"13111845716671250348"}},"outputId":"d88d339c-09af-4fd8-e443-8b8abaadf3e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5s.pt'], source=/content/yolov5/data/images, data=yolov5/data/coco128.yaml, imgsz=[832, 832], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=True, visualize=False, update=False, project=yolov5/runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 ðŸš€ v6.0-237-gdc7e093 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt to yolov5s.pt...\n","100% 14.0M/14.0M [00:00<00:00, 105MB/s] \n","\n","Fusing layers... \n","Model Summary: 213 layers, 7225885 parameters, 0 gradients\n","image 1/2 /content/yolov5/data/images/bus.jpg: 832x640 4 persons, 1 bus, Done. (0.113s)\n","image 2/2 /content/yolov5/data/images/zidane.jpg: 480x832 2 persons, 1 tie, Done. (0.151s)\n","Speed: 0.7ms pre-process, 131.7ms inference, 3.6ms NMS per image at shape (1, 3, 832, 832)\n","Results saved to \u001b[1myolov5/runs/detect/exp\u001b[0m\n"]}]},{"cell_type":"markdown","source":["## Observation\n","\n","As you can see the Mean Average Precision of the model trained from TTA has increased from 0.823 to 0.853."],"metadata":{"id":"tE0e6v53a0Fz"}},{"cell_type":"code","source":[""],"metadata":{"id":"minK6u3LYy8E"},"execution_count":null,"outputs":[]}]}