{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Model Ensembling Tutorial.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM752Rrvdnwq6kzttROqotM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["ðŸ“š This guide explains how to use YOLOv5 ðŸš€ model ensembling during testing and inference for improved mAP and Recall. UPDATED 25 January 2022.\n","\n","From https://www.sciencedirect.com/topics/computer-science/ensemble-modeling:\n","\n","Ensemble modeling is a process where multiple diverse models are created to predict an outcome, either by using many different modeling algorithms or using different training data sets. The ensemble model then aggregates the prediction of each base model and results in once final prediction for the unseen data. The motivation for using ensemble models is to reduce the generalization error of the prediction. As long as the base models are diverse and independent, the prediction error of the model decreases when the ensemble approach is used. The approach seeks the wisdom of crowds in making a prediction. Even though the ensemble model has multiple base models within the model, it acts and performs as a single model."],"metadata":{"id":"mnlLhpT8bTsZ"}},{"cell_type":"markdown","source":["#Before You Start"],"metadata":{"id":"eNRDloGwbNh2"}},{"cell_type":"markdown","source":["Clone repo and install requirements.txt in a Python>=3.7.0 environment, including PyTorch>=1.7. Models and datasets download automatically from the latest YOLOv5 release."],"metadata":{"id":"ag1dnRQ1bY10"}},{"cell_type":"code","source":["!git clone https://github.com/ultralytics/yolov5  # clone\n","%cd yolov5\n","!pip install -r requirements.txt  # install"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqwKS9htOJYT","executionInfo":{"status":"ok","timestamp":1644072093881,"user_tz":-360,"elapsed":6191,"user":{"displayName":"Boktiar Ahmed Bappy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih6IcON3wMQpvveeS9_REpH6y1XnnZEhx-zhFX=s64","userId":"10381972055342951581"}},"outputId":"afb04d62-f1c1-42c0-f880-2a22e463141d"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'yolov5'...\n","remote: Enumerating objects: 10878, done.\u001b[K\n","remote: Counting objects: 100% (12/12), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 10878 (delta 1), reused 7 (delta 0), pack-reused 10866\u001b[K\n","Receiving objects: 100% (10878/10878), 10.99 MiB | 24.73 MiB/s, done.\n","Resolving deltas: 100% (7510/7510), done.\n","/content/yolov5\n","Requirement already satisfied: matplotlib>=3.2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.2.2)\n","Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.19.5)\n","Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.1.2.30)\n","Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (7.1.2)\n","Collecting PyYAML>=5.3.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 596 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2.23.0)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (1.4.1)\n","Requirement already satisfied: torch>=1.7.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (1.10.0+cu111)\n","Requirement already satisfied: torchvision>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.11.1+cu111)\n","Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (4.62.3)\n","Requirement already satisfied: tensorboard>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (2.7.0)\n","Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (1.3.5)\n","Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (0.11.2)\n","Collecting thop\n","  Downloading thop-0.0.31.post2005241907-py3-none-any.whl (8.7 kB)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (3.0.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (2.8.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.2.2->-r requirements.txt (line 4)) (1.3.2)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.23.0->-r requirements.txt (line 9)) (2021.10.8)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.0->-r requirements.txt (line 11)) (3.10.0.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.35.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.3.6)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (57.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.37.1)\n","Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.43.0)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.8.1)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.0.0)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.6.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.17.3)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.4->-r requirements.txt (line 20)) (2018.9)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.15.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.2.4)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.8)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (4.10.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.7.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.4.1->-r requirements.txt (line 16)) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.4.1->-r requirements.txt (line 16)) (3.2.0)\n","Installing collected packages: thop, PyYAML\n","  Attempting uninstall: PyYAML\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed PyYAML-6.0 thop-0.0.31.post2005241907\n"]}]},{"cell_type":"markdown","source":["#Test Normally\n","\n","Before ensembling we want to establish the baseline performance of a single model. This command tests YOLOv5x on COCO val2017 at image size 640 pixels. yolov5x.pt is the largest and most accurate model available. Other options are yolov5s.pt, yolov5m.pt and yolov5l.pt, or you own checkpoint from training a custom dataset ./weights/best.pt. For details on all available models please see our README table."],"metadata":{"id":"bVFdI8rybe2M"}},{"cell_type":"code","source":["!python val.py --weights yolov5x.pt --data coco128.yaml --img 640 --half"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mXiUMZyxVLqZ","executionInfo":{"status":"ok","timestamp":1644072605196,"user_tz":-360,"elapsed":54474,"user":{"displayName":"Boktiar Ahmed Bappy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih6IcON3wMQpvveeS9_REpH6y1XnnZEhx-zhFX=s64","userId":"10381972055342951581"}},"outputId":"9aaacaae-70dc-4e8b-f8e9-578a75f0cfe2"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco128.yaml, weights=['yolov5x.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n","YOLOv5 ðŸš€ v6.0-236-gcba4303 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5x.pt to yolov5x.pt...\n","100% 166M/166M [00:02<00:00, 82.7MB/s]\n","\n","Fusing layers... \n","Model Summary: 444 layers, 86705005 parameters, 0 gradients\n","\n","Dataset not found, missing paths: ['/content/datasets/coco128/images/train2017']\n","Downloading https://ultralytics.com/assets/coco128.zip to coco128.zip...\n","100% 6.66M/6.66M [00:00<00:00, 76.2MB/s]\n","Dataset autodownload success, saved to /content/datasets\n","\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017' images and labels...128 found, 0 missing, 2 empty, 0 corrupt: 100% 128/128 [00:00<00:00, 1098.14it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/coco128/labels/train2017.cache\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:18<00:00,  4.69s/it]\n","                 all        128        929      0.798      0.752      0.823      0.623\n","Speed: 0.5ms pre-process, 120.4ms inference, 3.7ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp\u001b[0m\n"]}]},{"cell_type":"markdown","source":["#Ensemble Test\n","\n","Multiple pretraind models may be ensembled togethor at test and inference time by simply appending extra models to the --weights argument in any existing val.py or detect.py command. This example tests an ensemble of 2 models togethor:\n","\n","- YOLOv5x\n","- YOLOv5l6"],"metadata":{"id":"ul8lN274btNa"}},{"cell_type":"code","source":["!python val.py --weights yolov5x.pt yolov5l6.pt --data coco128.yaml --img 640 --half"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FZAy8bZ5XDx1","executionInfo":{"status":"ok","timestamp":1644072929025,"user_tz":-360,"elapsed":47309,"user":{"displayName":"Boktiar Ahmed Bappy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih6IcON3wMQpvveeS9_REpH6y1XnnZEhx-zhFX=s64","userId":"10381972055342951581"}},"outputId":"cf0469ce-6ec2-4e32-abc1-774a04ab177d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mval: \u001b[0mdata=/content/yolov5/data/coco128.yaml, weights=['yolov5x.pt', 'yolov5l6.pt'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False\n","YOLOv5 ðŸš€ v6.0-236-gcba4303 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Fusing layers... \n","Model Summary: 444 layers, 86705005 parameters, 0 gradients\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5l6.pt to yolov5l6.pt...\n","100% 147M/147M [00:01<00:00, 118MB/s]\n","\n","Fusing layers... \n","Model Summary: 476 layers, 76726332 parameters, 0 gradients\n","Ensemble created with ['yolov5x.pt', 'yolov5l6.pt']\n","\n","\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/coco128/labels/train2017.cache' images and labels... 128 found, 0 missing, 2 empty, 0 corrupt: 100% 128/128 [00:00<?, ?it/s]\n","               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 4/4 [00:29<00:00,  7.31s/it]\n","                 all        128        929      0.831      0.749      0.848      0.648\n","Speed: 0.3ms pre-process, 202.4ms inference, 3.6ms NMS per image at shape (32, 3, 640, 640)\n","Results saved to \u001b[1mruns/val/exp2\u001b[0m\n"]}]},{"cell_type":"markdown","source":["#Ensemble Inference\n","Append extra models to the --weights argument to run ensemble inference:"],"metadata":{"id":"Pvt045N_b3Wj"}},{"cell_type":"code","source":["!python detect.py --weights yolov5x.pt yolov5l6.pt --img 640 --source data/images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h23zVizMYUhp","executionInfo":{"status":"ok","timestamp":1644073555858,"user_tz":-360,"elapsed":9611,"user":{"displayName":"Boktiar Ahmed Bappy","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gih6IcON3wMQpvveeS9_REpH6y1XnnZEhx-zhFX=s64","userId":"10381972055342951581"}},"outputId":"2a5950f9-8461-482a-b3e8-d436828e8b41"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mdetect: \u001b[0mweights=['yolov5x.pt', 'yolov5l6.pt'], source=data/images, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False\n","YOLOv5 ðŸš€ v6.0-236-gcba4303 torch 1.10.0+cu111 CUDA:0 (Tesla K80, 11441MiB)\n","\n","Fusing layers... \n","Model Summary: 444 layers, 86705005 parameters, 0 gradients\n","Fusing layers... \n","Model Summary: 476 layers, 76726332 parameters, 0 gradients\n","Ensemble created with ['yolov5x.pt', 'yolov5l6.pt']\n","\n","image 1/2 /content/yolov5/data/images/bus.jpg: 640x512 4 persons, 1 bus, Done. (0.306s)\n","image 2/2 /content/yolov5/data/images/zidane.jpg: 384x640 3 persons, 3 ties, Done. (0.240s)\n","Speed: 0.6ms pre-process, 273.2ms inference, 3.8ms NMS per image at shape (1, 3, 640, 640)\n","Results saved to \u001b[1mruns/detect/exp\u001b[0m\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"eAP5FNrda22N"},"execution_count":null,"outputs":[]}]}